<!DOCTYPE html><html lang="en" class="serif"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>What's In a JPEG?</title><meta property="og:title" content="What's In a JPEG?"><meta property="og:type" content="website"><meta property="og:description" content="The fascinating algorithms behind an otherwise mundane image format."><meta name="description" content="The fascinating algorithms behind an otherwise mundane image format."><link rel="stylesheet" href="/stylesheets/highlight-style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><link rel="stylesheet" href="/stylesheets/main.css"><link rel="stylesheet" href="/blogposts/jpeg-explained/styles.css"><script defer src="/blogposts/jpeg-explained/jpeg.js"></script><script>const loadSetting = name => {
    if(localStorage.getItem(name) === "true")
        document.documentElement.classList.add(name);
    else
        document.documentElement.classList.remove(name);
};

loadSetting("serif");
loadSetting("darkmode");</script><script defer src="/scripts/ui.js"></script><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="canonical" href="https://blog.bithole.dev/blogposts/jpeg-explained"></head><body><header><a href="/"><img src="/images/banner.jpg" alt="blog banner"></a></header><main><noscript><p style="color: #ff0000">Warning: If you are seeing this message, JS isn't supported; unfortunately, since this page relies on JS to dynamically generate content, parts of the page may be missing or brutally disfigured.</p></noscript><p id="date" class="date">undefined NaN, NaN</p><h1 style="margin-top: 0">What's In a JPEG?</h1><nav><div id="contents"><p>Table of Contents</p><a href="#chroma-subsampling"><p>Chroma Subsampling</p></a><a href="#discrete-cosine-transform"><p>Discrete Cosine Transform</p></a><a href="#huffman-coding"><p>Huffman Coding</p></a><a href="#further-reading"><p>Further Reading</p></a></div><button id="show-toc">&#9776; Contents</button></nav><p>Recently, I set out to create my own photo organizer, a project which eventually bloomed into <a href="https://github.com/adrian154/photobox">Photobox</a>. In doing so, I came across a great deal of mucking about with image formats and compression, and then it dawned on me: JPEGs are ridiculously good at compressing image data, far beyond what seems possible! Take this picture, for example:</p>
<figure style="max-width: 299px">
    <img src="test-compressed.jpg" alt="a cormorant">
    <figcaption>This poor cormorant has no idea what he's about to go through.</figcaption>
</figure>

<p>This image is 299 by 400 pixels. Each pixel consists of three components, red, green, and blue. The brightness of each component is encoded as an 8-bit value, where 0 is no light emitted and 2^8 - 1 = 255 is the maximum brightness your display can muster. So, each pixel contains at least three bytes of information. Multiply that by the number of pixels, and we get a file size of around 350 kilobytes! Yet the image shown above is actually only 43kB in size, just 12% of the value we just calculated. In other words, by encoding the image using the JPEG format, we can achieve a compression ratio of roughly 8:1. How is such an astonishing ratio achievable? The trick is, much of the information within an image can be removed without resulting in a noticeable difference. Let&#39;s see how JPEG does it.</p>
<h1 id="chroma-subsampling">Chroma Subsampling <a class="section-link" href="#chroma-subsampling">&sect;</a></h1><p>The first method that JPEG uses to reduce the filesize is a technique called <strong>chroma subsampling</strong>. Essentially, this step exploits the fact that our eyes are much more sensitive to changes in brightness than to changes in color. After all, changes in brightness are how we primarily distinguish shapes and features. If you converted an image to black and white, you would still have a good idea of what the image is a picture of, whereas if you only had the color information it&#39;d convey much less detail. Thus, we can store the color information at a lower resolution than the brightness information without affecting the quality too much.</p>
<p>RGB isn&#39;t very conducive to chroma subsampling, though, because the brightness of the pixel is baked into all three channels. JPEG first converts the RGB pixel data to a color space called <a href="https://en.wikipedia.org/wiki/YCbCr">YCbCr</a>. Like RGB, YCbCr pixels also consist of three values; however, the meaning of the values are different. <strong>Y</strong> is the luminance (brightness) of the pixel, and <strong>Cb</strong> and <strong>Cr</strong> together represent the color of the pixel without any luminance info.</p>
<p>But how is RGB mapped to YCbCr? In my opinion, the relationship between the two color spaces is best explained visually. We can imagine RGB as a cube, with <em>x</em>-axis as red, <em>y</em>-axis as green, and <em>z</em>-axis as blue.</p>
<p><video class="center" loop controls autoplay><source src="rgb-cube-animation.mp4" type="video/mp4"></video></p>
<p>This cube has one important property: there exists a line through the cube where the R, G, and B values are all equal. One can imagine a coordinate system where we align the cube such that the luminance component (Y) extends along this line. We can then extract a slice of the cube for any given luminance, and assign the remaining two degrees of freedom to Cb and Cr.</p>
<p>This is essentially how YCbCr works, except the RGB values are first processed so that the cube ends up looking more like a slanted rectangular prism. (For the more math-inclined readers, you might recognize this as an affine transformation, hence why the RGB-YCbCr conversion is often described in terms of matrix multiplication). Here&#39;s a demo that shows the Cb-Cr planes as we adjust Y. </p>
<figure style="max-width: 480px">
    <video loop controls autoplay><source src="ycbcr-slices.mp4" type="video/mp4"></video>
    <figcaption>No, that Y is definitely not backwards.</figcaption>
</figure>

<p>If you want a better view of what the Cb-Cr plane looks like, here is a slice of the YCbCr gamut at Y = 0.5. </p>
<p><img src="ycbcr.png" alt="ycbcr diagram"></p>
<p>When an image is converted to JPEG, the first thing that happens is that the RGB colors are converted to YCbCr. The Cb and Cr channels are stored at half the resolution of the full image, a scheme which is referred to as <strong>4:2:0</strong>.</p>
<p>Let&#39;s compare what the components of the image look like in the two color spaces. Here&#39;s what the image looks like in RGB.</p>
<p><img src="rgb-components.png" alt="rgb components of the image"></p>
<p>And here&#39;s what the image looks like in YCbCr:</p>
<p><img src="ycbcr-components.png" alt="image in ycbcr color space"></p>
<p>As you can see, the importance of the luminance channel really shines through here. There is very little appreciable detail in the Cb and Cr channels, unlike in RGB space, where each channel is perceived roughly equally in the final image. We can safely discard much of the detail in the chrominance channels without sacrificing too much quality in the final image. However, this still doesn&#39;t bring us to the astounding compression ratios that JPEG achieves on a regular basis. For that, we&#39;ll need to go deeper into the compression process.</p>
<h1 id="discrete-cosine-transform">Discrete Cosine Transform <a class="section-link" href="#discrete-cosine-transform">&sect;</a></h1><p>In the previous step, we reduced size by getting rid of color information. However, we can also drastically reduce size by getting rid of unnecessary <em>spatial</em> information. What does that mean? Consider this photo of a flower.</p>
<p><img src="test-2-reference.png" alt="macro photograph of a pepper flower"></p>
<p>If we zoom in close on the two highlighted regions, it becomes clear that not all image data is created equal. The one on the left contains much more detail than the one on the right, yet they occupy the same amount of space.</p>
<p><img src="flower-regions-comparison.png" alt="zoom in on sections of flower image"></p>
<p>Like last time, the problem now becomes representing the image data in a way that lets us separate the important parts from the unimportant parts. JPEG accomplishes this by converting the image to the <strong>frequency domain</strong>.</p>
<p>To understand what that means, we need to start thinking of the image as a function. Right now, the image is best described as existing in the spatial domain, meaning it maps spatial inputs (pixel positions) to intensities. However, if you are familiar with the Fourier transform, you know that any signal can be expressed as the sum of sinusoidal waves.</p>
<p>The benefit of expressing the image in the frequency domain is that it allows us to discard unimportant high-frequency information. As we&#39;ll see later, we perceive low-frequency signals much more strongly than the higher frequency components.</p>
<p>JPEG does not use the Fourier transform; instead, it uses the closely related <a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform">discrete cosine transform</a>, whose characteristics make it better suited for use in lossy compression. Before we go further, try drawing a waveform below, and the signal as approximated by DCT will be shown on the right. You can use the slider to adjust the number of waveforms that are combined to form the approximation.</p>
<div id="dct-demo">
    <canvas id="signal" width="256" height="256"></canvas>
    <canvas id="transform" width="256" height="256"></canvas>
</div>

<input type="range" min="2" max="100" id="num-cosines">

<h1 id="huffman-coding">Huffman Coding <a class="section-link" href="#huffman-coding">&sect;</a></h1><h1 id="further-reading">Further Reading <a class="section-link" href="#further-reading">&sect;</a></h1><ul>
<li><a href="https://www.itu.int/rec/T-REC-T.871-201105-I/en">ITU - T.871: JPEG File Interchange Format (JFIF)</a></li>
<li><a href="https://www.w3.org/Graphics/JPEG/itu-t81.pdf">CCITT - T.81: Digital Compression and Coding of Continuous-Tone Still Images - Requirements and Guidelines</a></li>
<li><a href="https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/">Better Explained - An Interactive Guide to the Fourier Transform</a></li>
</ul>
<img id="img-view" style="display: none"><h1>Comments</h1><noscript><b>Please enable Javascript to view the comments on this post.</b></noscript><script src="https://utteranc.es/client.js" crossorigin="anonymous" repo="adrian154/blog" label="blog-post-comments" theme="preferred-color-scheme" issue-number="6"></script></main><footer><p>&copy; 2022 <a href="https://bithole.dev/">Adrian Zhang</a> &bull; <a href="/rss.xml">rss</a> &bull; <a href="https://github.com/adrian154/blog">source</a> &bull; <a href="https://creativecommons.org/licenses/by-sa/3.0/legalcode">CC BY-SA 3.0</a></p></footer></body></html>