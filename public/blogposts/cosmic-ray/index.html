<!DOCTYPE html><html lang="en" class="serif"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>Taking Pictures of Cosmic Rays</title><meta property="og:title" content="Taking Pictures of Cosmic Rays"><meta property="og:type" content="website"><meta property="og:description" content="Turn any digital camera into a radiation detector!"><meta name="description" content="Turn any digital camera into a radiation detector!"><link rel="stylesheet" href="/stylesheets/highlight-style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><link rel="stylesheet" href="/stylesheets/main.css"><script>const loadSetting = name => {
    if(localStorage.getItem(name) === "true")
        document.documentElement.classList.add(name);
    else
        document.documentElement.classList.remove(name);
};

loadSetting("serif");
loadSetting("darkmode");</script><script defer src="/scripts/ui.js"></script><link rel="icon" type="image/png" sizes="16x16" href="/favicon.png"><link rel="canonical" href="https://blog.bithole.dev/blogposts/cosmic-ray"></head><body><header><p><a id="home-link" href="/">« more posts</a></p><h1 id="post-title">Taking Pictures of Cosmic Rays</h1><p class="date">Published July 20, 2023</p></header><main><p>A blogpost? In this economy?! Yes, that&#39;s right. Today, we&#39;re going to be looking at how you can use an unmodified digital camera to detect cosmic rays and other charged particles.</p>
<p><img loading="lazy" src="title.png" alt="four cosmic rays"></p>
<p>First, what <em>is</em> a cosmic ray? They&#39;re not actually rays; rather, they are high-energy particles, usually protons, that have traveled through space to Earth. Some come from the sun, while others may originate from more distance sources in our galaxy or even other galaxies.</p>
<p>The original particle is called the primary cosmic ray, and it almost never makes it to the surface. Instead, when it collides with atoms in the atmosphere, a shower of secondary particles is produced. These particles are the ones which we&#39;ll be detecting. </p>
<p>To actually observe these particles, we&#39;ll be using a plain old digital camera. The silicon detector it uses to record the intensity of light is also sensitive to radiation; when charged particles pass through the sensor, electrons are ripped from the atoms of the photosites, producing charges that can be read out just like a regular image. This effect is sometimes seen as a white speckle pattern in photos of radioactive samples.</p>
<figure style="max-width: 500px">
    <img loading="lazy" src="rad-meme.jpg" alt="photo of radiation source with white dots">
    <figcaption>&#9835; Dumb ways to die, so many dumb ways to die... &#9835;</figcaption>
</figure>

<p>Anyways, the procedure is very simple. Just put the lens cap on your camera, put it in a dark place with the sensor facing the zenith (straight up), and leave it to take some pictures. With a little luck, you&#39;ll be greeted by some cosmic ray tracks in your images when you come back!</p>
<p>A few words about camera settings:</p>
<ul>
<li>In theory, a shorter exposure length offers many advantages, such as increased temporal resolution and less time for dark current to accumulate. However, this comes at the cost of more data to process and more shutter wear. I settled for an exposure length of 1 minute.</li>
<li>I used an ISO of 200, which corresponds to about unity gain (i.e. 1 electron equals 1 ADU) on my camera. ISO 100 would probably work well too. In general, a lower ISO is preferred since read noise is not a significant concern.</li>
</ul>
<p>One last tidbit: my camera, a Nikon D7000, applies some transformations to raw images such as black-point subtraction and channel scaling. This is great for regular photography, but it will screw up our data. Thankfully, there is a free <a href="https://nikonhacker.com/viewtopic.php?t=2319">tool</a> that uses USB commands to disable these adjustments.</p>
<p>As a bonus, this hack will also make the camera include the optical black pixels in the saved image. These pixels reside on the edge of the sensor and are blocked from receiving any light. Normally, they are used to calibrate the sensor&#39;s black point and are cropped from the final image, but cosmic rays can pass right through the opaque layer. Thus, we actually gain a tiny bit of extra detector area. </p>
<h1 id="post-processing">Post-processing <a class="section-link" href="#post-processing">&sect;</a></h1><p>I left my camera snapping away overnight, and woke up to 348 images. Let&#39;s open them up and take a look!</p>
<p>Upon first inspection, the images look totally black, which is hardly surprising. It&#39;s a picture taken with the lens cap on. What did you expect? </p>
<p>If we crank up the exposure a lot, some patterns start to appear:</p>
<p><img loading="lazy" src="hot-pixels.png" alt="hot pixels"></p>
<p>Wow, are those all cosmic rays? <em>No.</em> If you open up another exposure and go to the same spot, you will see the exact same patterns.</p>
<p>What we&#39;re dealing with is hot pixels. Every photosite will spontaneously produce electrons even in the absence of light due to thermal fluctuations; this signal is known as <em>dark current</em>. For most pixels, this is contained at about 0.1 electrons per second. However, due to flawed manufacturing, some pixels exhibit much higher dark current than others, manifesting as hot pixels.</p>
<p>It can be difficult to distinguish a hot pixel from a cosmic ray using just one frame of data, so instead we analyze the value of a pixel across multiple frames to check for anomalies. Hot pixels will show a consistent value in every frame, while a genuine cosmic ray hit will stand out.</p>
<p>Before we can get to messing with the images, we must convert them to a format that our code can read. My camera outputs images in Nikon&#39;s proprietary NEF format, which is not very amenable to manipulation. Luckily, there&#39;s an open-source tool called <a href="https://www.dechifro.org/dcraw/">dcraw</a> which will take our NEFs and produce <a href="https://en.wikipedia.org/wiki/Netpbm">PGMs</a>, which are basically just a short header followed by uncompressed pixel data.</p>
<p>If you are replicating my experiment, here is an example dcraw invocation:</p>
<pre><code class="hljs">dcraw -4 -D *.NEF</code></pre><ul>
<li><code>-4</code>: output linear 16-bit values</li>
<li><code>-D</code>: output a grayscale image</li>
</ul>
<p>These flags are very important. dcraw is designed to work with photographic data, so it will normally apply some adjustments to convert the raw data into a viewable image. For example, in order to record color, every photosite in the camera sensor is covered with a tinted filter in a <a href="https://en.wikipedia.org/wiki/Color_filter_array">repeating pattern</a>.</p>
<figure style="max-width: 320px">
    <img loading="lazy" src="bayer-matrix.png" alt="illustration of color filter array">
    <figcaption><a href="https://en.wikipedia.org/wiki/File:Bayer_pattern_on_sensor.svg">Image</a> by <a href="https://en.wikipedia.org/wiki/User:Cburnett">Cburnett</a> / <a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">CC BY-SA</a></figcaption>
</figure>

<p>dcraw will assign each pixel an (R,G,B) value by interpolating based on its neighbors, a process called <a href="https://en.wikipedia.org/wiki/Demosaicing">demosaicing</a>. However, the particles we&#39;re looking for aren&#39;t affected by the colored filters, so demosaicing will merely distort the data and thus must be avoided.</p>
<h2 id="anomaly-detection">Anomaly Detection <a class="section-link" href="#anomaly-detection">&sect;</a></h2><p>Disclaimer: my statistics knowledge pretty much peaked with AP Stats and has been going downhill since. So I&#39;m pretty much spitballing here. Beware!</p>
<p>In the absence of cosmic rays, the only signal we expect to observe is the dark current, which varies randomly due to <a href="https://en.wikipedia.org/wiki/Shot_noise">shot noise</a>. Shot noise follows a Poisson distribution, approaching a normal distribution under our conditions.</p>
<p><img loading="lazy" src="pixel-value-dist.png" alt="pixel value distribution showing bell curve"></p>
<p>Normality is confirmed by a normal probability plot:</p>
<p><img loading="lazy" src="normal-probability-plot.png" alt="normal probability plot showing linear distribution"></p>
<p>Incidentally, I totally forgot how to do these, so I wrote a short explanatory <a href="/blogposts/normality-plot/">blogpost</a> to refresh my memory.</p>
<p>Knowing all this, we can calculate a z-score for every sample, which essentially represents the number of standard deviations separating it from the mean. If this value is above a certain threshold, we mark the pixel in that frame as anomalous. I chose a cutoff of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">z = 6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">6</span></span></span></span>; theoretically, the odds of observing a value that extreme due to random variation alone are well below one in a billion. In reality, due to increasing dark current as the sensor heats up, the pixel values are not truly normally distributed and there will be occasional false positives.</p>
<p>In order to determine the z-scores, we must first compute the mean and standard deviation of each pixel. This turns out to be a bit problematic, since a na&iuml;ve algorithm requires all the values of the sample to be in memory. Unfortunately, the 11 GB of data we collected is a little too big for me to fit into memory. While there are <a href="https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford&#39;s_online_algorithm">algorithms</a> capable of computing mean and variance one value at a time in a single pass, I opted to calculate the sample mean and then the sum of the squared differences. This has the benefit of allowing me to remove the value in consideration from the mean and variance, preventing outliers from distorting the sample statistics.</p>
<aside>

<p>This is done based on the assumption that there will never be more than one outlier per pixel, which is reasonable considering that there are 17 million pixels per frame.</p>
</aside>

<p>The two-pass solution is slower, but by saving the computed values to a file and reusing it in subsequent analysis the computational cost is <a href="https://en.wikipedia.org/wiki/Amortized_analysis">amortized</a>. <s>Also, I have an SSD, so none of this is really relevant.</s></p>
<p>After identifying the anomalies, I grouped them into clusters by simply finding all other anomalies within a 16-pixel radius. This worked remarkably well, and allowed me to quickly find the most extensive cosmic ray patterns.</p>
<h2 id="cooling">Cooling <a class="section-link" href="#cooling">&sect;</a></h2><p>After collecting the first batch of data, I decided to do a little experiment. Recall that dark current is proportional to temperature. Therefore, by cooling the camera, we can significantly reduce the dark current level. I accomplished this by freezing my camera overnight.</p>
<figure>
    <img loading="lazy" src="camera-in-freezer.jpg" alt="camera, in ziploc bag, in freezer">
    <figcaption>Warning: not for consumption.</figcaption>
</figure>

<p>We can see just how much cooling affects noise by comparing the distribution of pixel values. I raised the exposure time to 10 minutes while in the freezer, so the variance of the real noise level is 10x lower.</p>
<p><img loading="lazy" src="dark-current-histogram.png" alt="histograms of pixels from warm and cold frames. warm bell curve is farther to right and more dispersed"></p>
<p>That&#39;s quite a reduction! Not only does the signal level go down, the distribution also becomes less dispersed. This is explained by the statistical properties of shot noise: its standard deviation is equal to the square root of the event rate. This can be used to determine the gain of the sensor at a given ISO; more on this in an upcoming blogpost!</p>
<aside>

<p>The high pixel value of the particle tracks means that this mild improvement in noise doesn&#39;t increase the SNR much, so this experiment doesn&#39;t benefit much from cooling. It is a neat trick, though.</p>
</aside>

<h1 id="results">Results <a class="section-link" href="#results">&sect;</a></h1><p>At a confidence level of 6 sigma, I was left with 15,150 anomalous pixels and 2,083 clusters of at least size 2. The cosmic ray flux at sea level is about 1 muon/cm<sup>2</sup>/minute, so we should expect to have seen about 1,300 cosmic rays over the course of our experiment. This disparity can be explained by the fact that some of the particles may be of terrestrial origin (i.e. ambient radioactive decay).</p>
<p>Cluster size appears to follow an exponential distribution:</p>
<p><img loading="lazy" src="cluster-size-distribution.png" alt="cluster size histogram showing that larger sizes rapidly become more uncommon"></p>
<p>Graphs are nice, but I wanted to see some actual images. So, I wrote a short script that would extract each identified cluster from the image, find the difference betweeh the value of each pixel and its mean (to correct for hot pixels), and plot the result. I co-opted one of <a href="https://github.com/liamedeiros/ehtplot">ehtplot</a>&#39;s colormaps for this purpose. I also applied some gamma correction at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo>=</mo><mn>0.7</mn></mrow><annotation encoding="application/x-tex">\gamma = 0.7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.7</span></span></span></span> to enhance feature visibility. </p>
<p>Here are the long-awaited images:</p>
<p><img loading="lazy" src="collage.png" alt="5x5 collage of cosmic rays"></p>
<p>What are these particles? The curved particles (&quot;worms&quot;) are most likely electrons; their low mass makes them easily deflected, hence the curved trajectories. These electrons are probably produced by Compton scattering of gamma rays emitted in the decay of naturally occuring radionuclides.</p>
<p><img loading="lazy" src="worm.png" alt="curved electron path"></p>
<p>The straight paths are most likely muons, produced by high-altitude air showers due to cosmic rays. </p>
<p><img loading="lazy" src="line.png" alt="straight muon path"></p>
<p>Distinguishing between the two is hardly an exact science, so... take all of this with a grain of salt.</p>
<p>Here are some shots from the freezer dataset:</p>
<p><img loading="lazy" src="44._DSC3441.pgm.9.png" alt="worm track split into three parts"></p>
<p><img loading="lazy" src="17._DSC3426.pgm.0.png" alt="multiple particles"></p>
<p>This next one&#39;s interesting: there&#39;s a trail, but it&#39;s dark. I did a little digging and discovered the cause of this artifact: a particle track occurred at that spot  in another frame, and its influence on the mean was so significant that when we subtracted it from the pixels, the imprint of that other track was left behind.</p>
<p><img loading="lazy" src="5._DSC3436.pgm.8.png" alt="dark track"></p>
<p>In some frames, we see not just one track but multiple spots. It&#39;s very likely that all of these particles were produced in the same air shower.</p>
<p><img loading="lazy" src="10._DSC3425.pgm.284.png" alt="multiple particles"></p>
<p><img loading="lazy" src="15._DSC3426.pgm.354.png" alt="multiple particles"></p>
<h1 id="closing-remarks">Closing Remarks <a class="section-link" href="#closing-remarks">&sect;</a></h1><p>I had a <em>lot</em> of fun with this project, and I&#39;m really glad that it turned out as well as it did! </p>
<p>If you&#39;re interested in replicating my experiment, my code is available on <a href="https://github.com/adrian154/cosmic-ray-detector">GitHub</a>. Warning: this was all written in quite a rush, so it may take some prodding to get it working. If you have any questions please feel free to reach out or leave a comment. You can also download my processed data <a href="data.zip">here</a>.</p>
<img id="img-view" style="display: none"><noscript><b>Please enable Javascript to view the comments on this post.</b></noscript><script src="https://utteranc.es/client.js" crossorigin="anonymous" repo="adrian154/blog" issue-term="title" label="blog-post-comments" theme="preferred-color-scheme"></script></main><footer><p>&copy; 2022 <a href="https://bithole.dev/">Adrian Zhang</a> &bull; <a href="/rss.xml">rss</a> &bull; <a href="https://github.com/adrian154/blog/tree/main/public/blogposts/cosmic-ray">source</a> &bull; <a href="https://creativecommons.org/licenses/by-sa/3.0/legalcode">CC BY-SA 3.0</a></p></footer></body></html>